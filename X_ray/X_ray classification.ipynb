{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08b9a44a-351d-4576-88c3-deb988386ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d732f4e9-564c-45a7-949f-ade50435f050",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "zip_path =r\"C:\\Users\\saran\\Desktop\\XRAY\\chest_xray-20250726T110654Z-1-001.zip\"\n",
    "extract_path = \"dataset\"\n",
    "\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_path)\n",
    "\n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435d2338-2eb6-41f4-8962-5c578606a913",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9875aa3c-eac3-4056-a005-3b5e2e915bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the training data directory\n",
    "datadir=r\"dataset/chest_xray/train/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e85bd57-cf91-4935-8340-c3deb1b23a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing the category of classification\n",
    "categories= ['normal','pneumonia']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a932a43-c8f5-4662-a957-72bfee81487a",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e662aad-d8a3-4dea-97ff-a32117c06b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852866eb-77ab-40ff-9910-65263aae844e",
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls dataset/chest_xray/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb28c00-a862-496c-8f04-14d48e80f721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the images to grayscale \n",
    "for i in categories: \n",
    "    path= os.path.join(datadir,i) \n",
    "    for img in os.listdir(path): \n",
    "        img_array= cv2.imread(os.path.join(path,img),cv2.IMREAD_GRAYSCALE) \n",
    "        plt.imshow(img_array, cmap='gray') \n",
    "        plt.show() \n",
    "        break \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a524ab-312b-4d62-9a47-2db95e188933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing the size of the image so that every image should be in same direction\n",
    "img_size=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2499f8ec-a46e-4513-98bc-238807df6e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image after resize and grayscale\n",
    "new_array = cv2.resize(img_array,(img_size,img_size))\n",
    "plt.imshow(new_array, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bd51a1-9ceb-4778-ab4a-484459c8d710",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e085ada3-7490-4ed1-ba43-30f95aa1b075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the funstion for training data according to the categories converting he images into gray scale\n",
    "# converting it into numpy arrays\n",
    "def create_training_data():\n",
    "    for i in categories:\n",
    "        path= os.path.join(datadir,i)\n",
    "        class_num= categories.index(i)\n",
    "\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_array=cv2.imread(os.path.join(path,img),cv2.IMREAD_GRAYSCALE)\n",
    "                new_array = cv2.resize(img_array,(img_size,img_size))\n",
    "                training_data.append([new_array,class_num])\n",
    "            except Exception as e:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a747272-e77d-4c67-8d0c-3458fa91c1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5960b968-fc39-4c3d-b111-969c57ae1600",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da02f658-9751-421d-a2be-08490831293c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(training_data)\n",
    "for sample in training_data[:10]:\n",
    "    print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b63c554-1c2b-4161-92c9-f9a254403a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the features and labels\n",
    "x=[]\n",
    "y=[]\n",
    "for features,label in training_data:\n",
    "    x.append(features)\n",
    "    y.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1888828d-3a3c-4d15-add7-b4d3946a8930",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x[0].reshape(-1,img_size,img_size,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca6108d-297f-45ce-b2f7-b28ac27144ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfa32c5-16b2-4ee7-bb85-c0221b81c9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshaping the features for making it compatible with tensorflow\n",
    "x= np.array(x).reshape(-1,img_size,img_size,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10d8301-f8b8-4788-9007-8d493eb28831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# as we do for training data similarlt doing with validation data\n",
    "validation_data=[]\n",
    "datadir_val=r\"dataset/chest_xray/val/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10526914-6aaa-4695-b988-026dd390f3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_validation_data():\n",
    "    for i in categories:\n",
    "        path= os.path.join(datadir_val,i)\n",
    "        class_num= categories.index(i)\n",
    "\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_array=cv2.imread(os.path.join(path,img),cv2.IMREAD_GRAYSCALE)\n",
    "                new_array = cv2.resize(img_array,(img_size,img_size))\n",
    "                validation_data.append([new_array,class_num])\n",
    "            except Exception as e:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a78c515-e0ab-4e5a-bb27-a8ffd11b2d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_validation_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053ffc1a-c99e-472d-9353-0c1c5a57d451",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(validation_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b990a4b1-039e-4dd5-a6af-51e73381e350",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(validation_data)\n",
    "for sample in validation_data[:10]:\n",
    "    print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6403f052-b058-49e6-93ba-ca2b1333d4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val=[]\n",
    "y_val=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49afd106-5e68-47f5-ba84-357c8a2aea5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for features,label in validation_data:\n",
    "    x_val.append(features)\n",
    "    y_val.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a30668-ab07-4af2-89c8-b5c0a3b65281",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val=np.array(x_val).reshape(-1,img_size,img_size,1)\n",
    "y_val=np.array(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0745efe-2cc1-4735-9534-7c5581e6cfa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the library for training the model and adding the neural networj layers\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout, Activation, Flatten\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8782eac4-03e3-40d4-a053-3bbfdffcd488",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a96bb1-a741-46d6-a823-b5944b8942f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=x/255.0\n",
    "x_val=x_val/255.0 \n",
    "# this is feature scaling step (in order to scale it down from 0 to 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b62f98-e279-43f3-993f-4753b41c35e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55d1162-01ca-40b2-b30b-93db5780b57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model the neural network layer for training the model\n",
    "model= Sequential()\n",
    "\n",
    "model.add(Conv2D(64,(3,3),input_shape=x.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(.2))\n",
    "\n",
    "model.add(Conv2D(128,(3,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(.2))\n",
    "\n",
    "model.add(Conv2D(256,(3,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(.2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "\n",
    "model.add(Dropout(.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb95ec2a-74c6-48aa-928c-5764fcf9a8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5fb555-c03f-425d-85df-a7431f7f0020",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss= 'binary_crossentropy', optimizer ='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0f83fb-f4d7-4cb2-b2f6-6b49174a4e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting the model with 10 epochs and using the validation data we have created\n",
    "model.fit(x,y,batch_size=4, epochs=10, validation_data= (x_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69a8243-95fb-45b2-a3c1-589e3fc0c716",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(r'model_10.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdf45f4-61e7-4149-8b59-4512a77437f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4421b1-1e51-4426-a093-1b493b26b750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for preparing the image for predicting the class\n",
    "def prepare(image):\n",
    "    img_size=100\n",
    "    # img_array= cv2.imread(image,cv2.IMREAD_GRAYSCALE)\n",
    "    img= tf.keras.preprocessing.image.load_img(image, color_mode='grayscale', target_size=(img_size,img_size))\n",
    "    new_array=tf.keras.preprocessing.image.img_to_array(img)\n",
    "\n",
    "    return new_array.reshape(-1,img_size,img_size,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f50a08-5286-4c56-8356-ba9f0514fb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=tf.keras.models.load_model(r'model_10.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bc23e6-2a39-45dd-902b-2877693ed465",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = r\"C:\\Users\\saran\\Desktop\\ML\\X_ray\\dataset\\chest_xray\\test\\PNEUMONIA\\person16_virus_47.jpeg\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a05cb3e-a751-409f-8967-599b4edbd968",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict([prepare(image)/255.0])\n",
    "print(prediction)\n",
    "print(round(prediction[0][0]))\n",
    "print(categories[int(round(prediction[0][0]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3219ff-00f7-426c-9ccf-2d5eb39c2831",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = r'C:\\Users\\saran\\Desktop\\XRAY\\dataset\\chest_xray\\test'\n",
    "model =load_model(r\"C:\\Users\\saran\\Desktop\\ML\\X_ray\\model_10.h5\")\n",
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "# Loop through the test data directory and extract the images and their labels\n",
    "for category in categories:\n",
    "    path = os.path.join(test_dir,category)\n",
    "    class_num = categories.index(category)\n",
    "    for img in os.listdir(path):\n",
    "        try:\n",
    "            img_array = cv2.imread(os.path.join(path,img), cv2.IMREAD_GRAYSCALE)\n",
    "            new_array = cv2.resize(img_array, (img_size, img_size))\n",
    "            x_test.append(new_array)\n",
    "            y_test.append(class_num)\n",
    "        except Exception as e:\n",
    "            pass\n",
    "\n",
    "# convert test data to numpy arrays\n",
    "x_test = np.array(x_test).reshape(-1,img_size,img_size,1)\n",
    "y_test= np.array(y_test)\n",
    "\n",
    "#normalize test data\n",
    "x_test =x_test/255.0\n",
    "\n",
    "# calculate test accuracy\n",
    "test_loss, test_acc =model.evaluate(x_test,y_test, verbose=2)\n",
    "\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c110d8f-443b-45a4-ad4e-916118cbffc6",
   "metadata": {},
   "source": [
    "## Pre Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a3219b-f983-4b82-94e3-8de77c0e4efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a592f71-86e7-41b0-9860-a58b92b99ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEFINE IMAGE SIZE\n",
    "img_size=100\n",
    "\n",
    "# load the pre_trained model (VGG16)\n",
    "base_model = VGG16(input_shape = (img_size,img_size,3), include_top= False, weights = 'imagenet')\n",
    "\n",
    "# freeze the layers of the pre trained model\n",
    "for layer in  base_model.layers:\n",
    "    layer.trainable= False\n",
    "\n",
    "# add custom layers for classification\n",
    "x= Flatten()(base_model.output)\n",
    "x= Dense(256, activation='relu')(x)\n",
    "x= Dense(128, activation='relu')(x)\n",
    "x= Dense(64, activation='relu')(x)\n",
    "predictions= Dense(1, activation= 'sigmoid')(x)\n",
    "\n",
    "#create a new model \n",
    "model= Model(inputs= base_model.input, outputs= predictions)\n",
    "\n",
    "#compile the model\n",
    "model.compile(optimizer='adam', loss= 'binary_crossentropy' , metrics=['accuracy'])\n",
    "\n",
    "# define the image generators for training and validation data\n",
    "train_datagen= ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip= True)\n",
    "val_datagen= ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "#specify the training and validation data directories\n",
    "train_dir = r\"C:\\Users\\saran\\Desktop\\ML\\X_ray\\dataset\\chest_xray\\train\"\n",
    "val_dir = r\"C:\\Users\\saran\\Desktop\\ML\\X_ray\\dataset\\chest_xray\\val\"\n",
    "\n",
    "#create the image generators for training and validation data\n",
    "train_generator= train_datagen.flow_from_directory(train_dir, target_size=(img_size,img_size), batch_size=32, class_mode='binary')\n",
    "val_generator= val_datagen.flow_from_directory(val_dir, target_size=(img_size,img_size), batch_size=32, class_mode='binary')\n",
    "\n",
    "#train the model\n",
    "model.fit(train_generator, epochs=10, validation_data= val_generator)\n",
    "\n",
    "# evaluate the model on test data\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator =test_datagen.flow_from_directory(test_dir, target_size=(img_size,img_size), batch_size=32, class_mode='binary', shuffle=False)\n",
    "test_loss, test_acc = model.evaluate(test_generator)\n",
    "print('Test accuracy:', test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775a7919-0d95-4655-b2e2-a3506ef8ce88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here it is clear that we are getting better accuracy than our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7435168-79c8-4526-be82-1117753e72e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
